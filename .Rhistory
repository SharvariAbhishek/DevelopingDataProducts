xlab("Transmission Type")+ylab(Miles per gallon)
p <- ggplot(mtcars, aes(am, mpg))+geom_boxplot(aes(fill = am))
p <- p+xlab("Transmission Type")+ylab(Miles per gallon)
p <- ggplot(mtcars, aes(am, mpg))+geom_boxplot(aes(fill = am))
p <- p+xlab("Transmission Type")+ylab("Miles per gallon")
print(p)
p <- ggplot(mtcars, aes(am, mpg))+geom_boxplot(aes(fill = am))
+xlab("Transmission Type")+ylab("Miles per gallon")
p <- ggplot(mtcars, aes(am, mpg))+geom_boxplot(aes(fill = am))
p+xlab("Transmission Type")+ylab("Miles per gallon")
print(p)
p <- ggplot(mtcars, aes(am, mpg))+geom_boxplot(aes(fill = am))
p+xlab("Transmission Type")+ylab("Miles per gallon")
pairs(mpg~., data = mtcars)
par(mfrow = c(2,2))
plot(fit_mvr)
fit_mvr <- lm(mpg~qsec, data = mtcars)
summary(fit_mvr)
fit_mvr <- lm(mpg~ wt+qsec, data = mtcars)
summary(fit_mvr)
fit_mvr <- lm(mpg~ wt+qsec+am, data = mtcars)
summary(fit_mvr)
View(mtcars)
fit_max <- lm(mpg~am+wt+cyl+disp+gear, data = mtcars)
anova(fit_linear, fit_mvr, fit_max, fit_all)
fit_max <- lm(mpg~am+wt+cyl+disp+hp, data = mtcars)
anova(fit_linear, fit_mvr, fit_max, fit_all)
install.packages(caret)
install.packages("caret")
library(caret)
library(kernlab)
data(spam)
View(spam)
str(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
?createDataPartition
inTrain
View(inTrain)
training <- spam[inTrain, ]
View(training)
testing <- spam[-inTrain,]
View(testing)
dim(training)
?set.seed
set.seed(32343)
modelfit <- train(type ~ . , data = training, method = "glm")
install.packages('e1071', dependencies=TRUE)
modelfit <- train(type ~ . , data = training, method = "glm")
modelfit
modelfit$finalModel
prediction <- predict(modelfit, newdata = testing)
prediction
confusionMatrix(prediction, testing$type)
set.seed(32323)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE)
sapply(folds, length)
folds[[1]][1:10]
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = FALSE)
sapply(folds, length)
folds[[1]][1:10]
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE)
folds
sapply(folds, length)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = FALSE)
folds
sapply(folds, length)
folds[[1]][1:10]
folds <- createResample(y = spam$type, times = 10, list = TRUE)
folds
sapply(folds,length)
folds[[1]][1:10]
names(folds)
set.seed(32323)
tme <- 1:1000
createTimeSlices(tme, initialWindow = 20, horizon = 10)
folds <- createTimeSlices(tme, initialWindow = 20, horizon = 10)
folds
names(folds)
folds$train[[1]]
folds$test[[1]]
folds$test[[2]]
folds$test[[3]]
folds$test[[10]]
folds$test[[20]]
folds$test[[50]]
args(train.default)
args(train)
args(train.default)
args(trainControl)
modelfit2 <- train(type ~ ., data = training, method = "glm")
modelfit2
set.seed(1235)
modelfit3 <- train(type ~ ., data = training, method = "glm")
install.packages("ISLR")
library(ISLR)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
View(inTrain)
View(Wage)
training <- Wage[inTrain, ]
View(training)
testing <- Wage[-inTrain,]
View(testing)
dim(training)
dim(testing)
featurePlot(x = training[, c("age", "education", "jobclass")], y = training$wage, plot = "pairs")
qplot(age, wage, data = training)
qplot(age, wage, color = jobclass , data = training)
qq <- qplot(age, wage, color = education , data = training)
qq+geom_smooth(method = "lm", formula = y ~ x)
cutwage <- cut2(training$wage, g = 3)
library(Hmisc)
cutwage <- cut2(training$wage, g = 3)
table(cutwage)
p <- qplot(cutwage, age, data = training, fill= cutwage, geom = c("boxplot"))
p
t1 <- table(cutwage, training$jobclass)
t1
prop.table(t1, 1)
qplot(wage, color = education, data = training, geom = "density")
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
View(training)
hist(training$capitalAve, main =  "", xlab = "ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapitalAve <- training$capitalAve
trainCapitalAves <- (trainCapitalAve - mean(trainCapitalAve))/sd(trainCapitalAve)
mean(trainCapitalAves)
sd(trainCapitalAves)
testCapitalAve <- testing$capitalAve
testCapitalAves <- (testCapitalAve - mean(testCapitalAve))/sd(testCapitalAve)
mean(testCapitalAves)
sd(testCapitalAves)
preObj <- preProcess(training[,-58], method = c("center", "scale"))
trainCapitalAves <- predict(preObj, training[, -58])$capitalAve
trainCapitalAves
mean(trainCapitalAves)
sd(trainCapitalAves)
testCapitalAves <- predict(preObj, testing[, -58])$capitalAve
mean(testCapitalAves)
sd(testCapitalAves)
preObj <- preProcess(training[,-58], method = c("BoxCox"))
trainCapitalAves <- predict(preObj, training[, -58])$capitalAve
par(mfrow=c(1,2));hist(trainCapitalAves);qqnorm(trainCapitalAves)
set.seed(13343)
training$capAve <- training$capitalAve
training$capAve
dim(training)[1]
?rbinom
selectNA <- rbinom(dim(training)[1], size = 1, prob = 0.05) == 1
selectNA
training$capAve[selectNA]
training$capAve[selectNA] <- NA
training$capAve
library(caret)
preObj <- preProcess(training[, -58], method = "knnImpute")
capAve <- predict(preObj, training[,-58])$capAve
install.packages("RANN")
library(RANN)
capAve <- predict(preObj, training[,-58])$capAve
capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth - mean(capAveTruth))/sd(capAveTruth)
capAveTruth
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
inTrain1  <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
View(spam)
View(inTrain1)
training1 <- Wage[inTrain1,]
testing1 <- Wage[-inTrain1,]
View(testing1)
table(training1$jobclass)
dummies <- dummyVars(wage ~ jobclass, data = training1)
head(predict(dummies, newdata = training1))
nsv <- nearZeroVar(training1, saveMetrics = TRUE)
nsv
?nearZeroVar
library(splines)
?bs
bsbasis <- bs(training1$age, df = 3)
bsbasis
lm1 <- lm(wage ~ bsbasis, data = training1)
lm1
plot(training1$age, training1$wage, pch = 19, cex = 0.5)
points(training1$age, predict(lm1, newdata = training1), col = "red",  pch = 19, cex = 0.5)
predict(bsbasis, age = testing1$age)
View(training)
dim(training)
names(training)
training <- spam[inTrain,]
dim(training)
testing <- spam[-inTrain,]
cor(training[-58])
abs(cor(training[-58]))
M <- abs(cor(training[-58]))
View(M)
diag(M) <- 0
View(M)
which(M > 0.8, arr.ind = T)
names(spam)[c(34,32,40)]
plot(spam[,34], spam[,32])
X <- 0.71*training$num415+0.71*training$num857
Y <- 0.71*training$num415-0.71*training$num857
plot(X,Y)
X
Y
smallSpam <- spam[, c(34,32)]
View(smallSpam)
prComp <- prcomp(smallSpam)
prComp
plot(prComp$x[,1], prComp$x[,2])
x
prComp$x
prComp$ro
tation
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
View(adData)
testIndex <- createDataPartition(diagnosis, p =0.50, list = FALSE)
trainIndex <- adData[testIndex,]
View(testIndex)
testingIndex <- adData[-testIndex,]
View(trainIndex)
View(testingIndex)
166+167
data(AlzheimerDisease)
diagnosis
adData <- data.frame(diagnosis, predictors)
testIndex <- createDataPartition(diagnosis, p =0.50, list = FALSE)
testingIndex <- adData[-testIndex,]
trainIndex <- adData[testIndex,]
train <- createDataPartition(diagnosis, p =0.50, list = FALSE)
test <- createDataPartition(diagnosis, p =0.50, list = FALSE)
View(train)
View(test)
View(testIndex)
train1 <- adData[train,]
test1 <- adData[test,]
View(test1)
View(train1)
View(test1)
View(train)
View(test)
rm(test1,test,train,train1)
data("concrete")
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
inTrain
training <- mixtures[inTrain, ]
testing <- mixtures[-inTrain,]
library(Hmisc)
name <- colnames(concrete)
name <- name[-length(name)]
name
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[, name], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
index
ggplot(data = training, aes(x = index, y = CompressiveStrength))+geom_point()+theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(x = index, y = cutCs))+geom_boxplot()+geom_point()+theme_bw()
ggplot(data = training, aes(x = index, y = cutCS))+geom_boxplot()+geom_point()+geom_jitter(col = "blue")+theme_bw()
ggplot(data = training, aes(y = index, x = cutCS))+geom_boxplot()+geom_point()+geom_jitter(col = "blue")+theme_bw()
featurePlot(x=training[, name], y = cutCS, plot = "pairs")
featurePlot(x=training[, name], y = cutCS, plot = "box")
hist(training$Superplasticizer, breaks = 20)
hist(log(training$Superplasticizer+1), breaks = 20)
rm(trainIndex,testingIndex,testIndex)
inTrainAl <- createDataPartition(adData$diagnosis, p =3/4)[[1]]
trainAl <- adData[inTrainAl,]
testAl <- adData[-inTrainAl]
testAl <- adData[-inTrainAl, ]
str(trainAl)
which(sapply(adData, class) == "factor")
summary(trainAl$diagnosis)
trainAl$diagnosis <- as.numeric(trainAl$diagnosis)
which(sapply(adData, class) == "factor")
p <- prcomp(trainAl[, grep('^L', names(trainAl))])
p$rotation[, 1:7]
p$rotation
qplot(1:length(p$sdev)/sum(p$sdev))
qplot(1:length(p$sdev), p$sdev/sum(p$sdev))
which(cumsum(p$sdev)/sum(p$sdev) <= .9)
(cumsum(p$sdev)/sum(p$sdev))[3]
preproc <- preProcess(trainAl[, grep('^IL', names(trainAl))], method = "pca", thresh = .9)
preproc
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- read.csv(url(trainurl), na.strings = c("", "NA"))
testFile <- read.csv(url(testurl), na.strings = c("", "NA"))
dim(trainFile)
dim(testFile)
trainFile <- trainFile[,colSums(is.na(trainFile)) == 0]
testFile <- testFile[, colSums(is.na(testFile)) == 0]
#We also remove the first seven predictors since these variables have little predicting power for the outcome `classe`
trainFile <- trainFile[, -c(1:7)]
testFile <- testFile[, -c(1:7)]
dim(trainFile)
dim(testFile)
set.seed(12345)
inTrain <- createDataPartition(trainFile$classe, p = 0.7, list = FALSE)
library(caret)
library(rattle)
library(rpart)
library(rpart.plot)
library(randomForest)
set.seed(12345)
inTrain <- createDataPartition(trainFile$classe, p = 0.7, list = FALSE)
Train <- trainFile[inTrain,]
Test <- trainFile[-inTrain,]
dim(Train)
dim(Test)
set.seed(12345)
modTree <- train(classe ~ ., data = Train, method = "rpart")
modTree
prediction1 <- predict(modTree, newdata= Test)
print(confusionMatrix(prediction1, Test$classe), digits = 4)
set.seed(12345)
model_rf <- randomForest(classe ~ . , data = Train)
model_rf
prediction2 <- predict(model_rf, newdata = Test)
print(confusionMatrix(prediction2, Test$classe), digits = 4)
prediction1 <- predict(modTree, newdata= Test)
print(confusionMatrix(prediction1, Test$classe), digits = 4)
prediction2 <- predict(model_rf, newdata = Test)
print(confusionMatrix(prediction2, Test$classe), digits = 4)
set.seed(12345)
model_rf <- randomForest(classe ~ . , data = Train)
model_rf
prediction1 <- predict(modTree, newdata= Test)
rpart_c <- confusionMatrix(prediction1, Test$classe)
rpart_c
set.seed(12345)
model_rf <- randomForest(classe ~ . , data = Train)
model_rf$finalModel
set.seed(12345)
modTree <- train(classe ~ ., data = Train, method = "rpart")
summary(modTree)
set.seed(12345)
modTree <- train(classe ~ ., data = Train, method = "rpart")
summary(modTree)
set.seed(12345)
modTree <- train(classe ~ ., data = Train, method = "rpart")
modTree$finalModel
set.seed(12345)
modTree <- train(classe ~ ., data = Train, method = "rpart")
modTree
out_sam_err <- 1 - rpart_c$overall[[1]]
out_sam_err <- out_sam_err*100
out_sam_err
out_sam_err <- 1 - rpart_c$overall[1]
out_sam_err <- out_sam_err*100
out_sam_err
out_sam <- 1 - rpart_c$overall[1]
out_sam_err <- out_sam*100
out_sam_err
prediction1 <- predict(modTree, newdata= Test)
print(confusionMatrix(prediction1, Test$classe))
prediction2 <- predict(model_rf, newdata = Test)
print(confusionMatrix(prediction2, Test$classe))
set.seed(12345)
model_rf <- randomForest(classe ~ . , data = Train)
model_rf
prediction2 <- predict(model_rf, newdata = Test)
print(confusionMatrix(prediction2, Test$classe))
prediction2 <- predict(model_rf, newdata = Test)
rf_c <-confusionMatrix(prediction2, Test$classe)
rf_c
oos_rf <- 1 - rf_c$overall[1]
oos_rf
oos_rf <- 1 - rf_c$overall[1]
oos_rf
oos_rf <- oos_rf*100
oos_rf
outOfSampleError.accuracy <- sum(prediction2 == Test$classe)/length(prediction2)
outOfSampleError.accuracy
oos_rf <- 1 - outOfSampleError.accuracy
oos_rf
oos_rf <- oos_rf*100
oos_rf
testingPrediction <- predict(model_rf, newdata = testFile)
testingPrediction
?generalization_error
??generalization_error
install.packages("regclass")
install.packages("VGAM")
install.packages("VGAM", type = "source")
R CMD INSTALL -l /home/abhishekdg/Downloads/VGAM_1.0-4.tar.gz
View(Train)
install.packages("psych")
library(caret)
library(rattle)
library(rpart)
library(randomForest)
library(psych)
pairs.panels(Train[,1:5],
method = "pearson", # correlation method
hist.col = "#00AFBB",
density = TRUE,  # show density plots
ellipses = TRUE # show correlation ellipses
)
View(Train)
names(Train)
pairs.panels(Train[,-53],
method = "pearson", # correlation method
hist.col = "#00AFBB",
density = TRUE,  # show density plots
ellipses = TRUE # show correlation ellipses
)
fancyRpartPlot(modTree)
fancyRpartPlot(modTree$finalModel)
install.packages("plotly")
data(diamond)
data("WWWusage")
summary(WWWusage)
str(WWWusage)
data("trees")
str(trees)
trees?
?
exit
data(sleep)
str(sleep)
View(sleep)
knitr::opts_chunk$set(echo = FALSE)
suppressWarnings(suppressMessages(library(plotly)))
data(sleep)
str(sleep)
suppressWarnings(suppressMessages(library(plotly)))
data(sleep)
str(sleep)
View(sleep)
sleep$group[which(sleep$group == 1)] <- 'DrugType-1'
sleep$group[which(sleep$group == 2)] <- 'DrugType-2'
sleep$group <- as.factor(sleep$group)
p <- plot_ly(sleep, x= ~extra, y = ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>% add_markers() %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'drug given'),
zaxis = list(title = 'patient ID')))
sleep$group[which(sleep$group == 1)] <- 'DrugType-1'
sleep$group[which(sleep$group == 2)] <- 'DrugType-2'
sleep$group <- as.factor(sleep$group)
p <- plot_ly(sleep, x= ~extra, y = ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>% add_markers() %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'drug given'),
zaxis = list(title = 'patient ID')))
p <- plot_ly(sleep, x= ~extra, y = ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>% add_markers() %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'drug given'),
zaxis = list(title = 'patient ID')))
p <- plot_ly(sleep, x= ~extra, y = ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>% add_markers() %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'drug given'),
zaxis = list(title = 'patient ID')))
p <- plot_ly(sleep, x= ~extra, y = ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>% add_markers() %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'patient ID'))
p <- plot_ly(sleep, x= ~extra, y = ~ID, color = ~group) %>%
layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'patient ID'))
p <- plot_ly(sleep, x= ~extra, y = ~ID)
setwd("~/Desktop/MyWorkSpace/DevelopingDataProducts")
p <- plot_ly(sleep, x= ~extra, y = ~ID)
p <- plot_ly(sleep, x= ~extra, y = ~ID)
p
p <- plot_ly(sleep, x= ~extra, y = ~ID, color = ~group)
p
p <- plot_ly(sleep, x= ~extra, y = ~ID, color = ~group, colors = "Set1")
p
p <- plot_ly(sleep, x= ~extra, y = ~ID, type = "scatter", mode = "markers")
p
p <- plot_ly(sleep, x= ~extra, y = ~ID, type = "scatter", mode = "markers", marker = list(size = 10, color = ~group))
p
p <- plot_ly(sleep, x= ~extra, y = ~ID, type = "scatter", mode = "markers", color = ~group)
p
View(sleep)
data(sleep)
str(sleep)
p <- plot_ly(sleep, x= ~extra, y = ~ID, type = "scatter", mode = "markers", color = ~group)
p
sleep$group[which(sleep$group == 1)] <- 'drugType-1'
View(sleep)
data(sleep)
as.numeric(sleep$group)
str(sleep)
p <- plot_ly(sleep, x= ~extra, y= ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers()
p
p <- plot_ly(sleep, x= ~extra, y= ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>% layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'Drug given'),
zaxis = list(title = 'Patient's ID)))
p <- plot_ly(sleep, x= ~extra, y= ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>% layout(scene = list(xaxis = list(title = 'Extra hours slept'),
yaxis = list(title = 'Drug given'),
zaxis = list(title = 'Patient ID')))
p
p <- plot_ly(sleep, x= ~extra, y= ~group, z= ~ID, color = ~group, colors = c('#BF382A', '#0C4B8E')) %>%
+   add_markers() %>% layout(scene = list(xaxis = list(title = 'Extra hours slept'),
+                      yaxis = list(title = 'Drug given'),
+                      zaxis = list(title = 'Patient ID')))
install.packages(DDPQuiz3)
